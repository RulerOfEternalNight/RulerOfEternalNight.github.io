---
title: "Hyperparameter Optimization with Genetic Algorithm and Simulated Annealing"
excerpt: "<small><i>Get pip package: [Visit](https://pypi.org/project/jss-optimizer/)</i><br/></small>
This repository [Link](https://github.com/RulerOfEternalNight/JSS_HybridOptimizier) contains a Python package `jss-optimizer` for optimizing hyperparameters using genetic algorithm (GA) and simulated annealing (SA) hybrid optimization algorithm.

<br/><br/>
<img src='/images/Slide7.png' width='400' height='300' style='margin-bottom: 20px;'>
<img src='/images/pypiPrj.png' width='400' height='300' style='margin-bottom: 20px;'>"

collection: portfolio
---

**Overview:** 
Optimizing hyperparameters is crucial for enhancing the performance of machine learning models. This project presents a hybrid optimization algorithm that combines Genetic Algorithm (GA) and Simulated Annealing (SA) to efficiently search and fine-tune hyperparameters, leading to more accurate and robust models.

## Based on the paper:
*J. S. Saravanan and A. Mahadevan, "AI based parameter estimation of ML model using Hybrid of Genetic Algorithm and Simulated Annealing," 2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT), Delhi, India, 2023, pp. 1-5, doi: 10.1109/ICCCNT56998.2023.10308077.* [Visit ↗️](https://rulerofeternalnight.github.io/publication/2009-10-01-paper-title-number-1)

---
<br>

**Key Features:**

- **Hybrid Optimization Approach:** Utilizes a unique combination of Genetic Algorithm (GA) and Simulated Annealing (SA) to leverage the strengths of both algorithms—GA’s ability to explore a wide search space and SA’s capability to fine-tune solutions for local optimization.
- **Versatile Application:** The optimization method is adaptable to various machine learning models and tasks, providing a powerful tool for model tuning across different domains.
- **User-Friendly Python Package:** The project is encapsulated in a Python package called jss-optimizer, making it easy for developers and researchers to implement and integrate into their own workflows.


**Project Highlights:**

- **Enhanced Optimization Efficiency:** The hybrid approach significantly improves the efficiency of hyperparameter tuning by reducing the computational overhead associated with exhaustive search methods.
- **Accessible and Open-Source:** The jss-optimizer package is available on GitHub, allowing users to easily access, modify, and contribute to the project.
- **Extensive Testing and Validation:** The algorithm has been tested across various machine learning tasks, demonstrating its capability to enhance model performance through effective hyperparameter optimization.

**Technologies Used:**

- **Programming Language:** Python
- **Optimization Algorithms:** Genetic Algorithm (GA), Simulated Annealing (SA)
- **Software Development:** Python packaging for easy distribution and integration

**Outcome:** The "Hyperparameter Optimization with Genetic Algorithm and Simulated Annealing" project showcases a novel approach to hyperparameter tuning, combining the explorative power of GA with the refining capabilities of SA. The resulting jss-optimizer package provides a practical solution for developers and data scientists seeking to maximize model performance with minimal effort.

**Get the Python Package:** To get started with jss-optimizer, visit the repository link for installation instructions and documentation.

Pipy Link to the package: [Pipy](https://pypi.org/project/jss-optimizer/)
